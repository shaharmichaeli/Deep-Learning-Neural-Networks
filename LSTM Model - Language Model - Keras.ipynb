{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HomeWork_4_ShaharMichaeli.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Exercise 4 - LSTM\n",
        "Shahar Michaeli\n"
      ],
      "metadata": {
        "id": "m493x25CUrwK"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eUqwGZDUt-NM"
      },
      "source": [
        "## Imports and Configurations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mT21eZYEznBE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd4a20fa-8484-42ad-8a8e-a4b0d9b7cd18"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "!pip install tensorboardX\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))\n",
        "\n",
        "# !git clone https://github.com/pbloem/language-models.git\n",
        "!git clone https://github.com/GuyKabiri/language_models"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorboardX\n",
            "  Downloading tensorboardX-2.4.1-py2.py3-none-any.whl (124 kB)\n",
            "\u001b[K     |████████████████████████████████| 124 kB 4.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from tensorboardX) (1.19.5)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorboardX) (3.17.3)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.8.0->tensorboardX) (1.15.0)\n",
            "Installing collected packages: tensorboardX\n",
            "Successfully installed tensorboardX-2.4.1\n",
            "Found GPU at: /device:GPU:0\n",
            "Cloning into 'language_models'...\n",
            "remote: Enumerating objects: 106, done.\u001b[K\n",
            "remote: Total 106 (delta 0), reused 0 (delta 0), pack-reused 106\u001b[K\n",
            "Receiving objects: 100% (106/106), 19.38 MiB | 8.82 MiB/s, done.\n",
            "Resolving deltas: 100% (55/55), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rXVfQ22TWhuN"
      },
      "source": [
        "import keras\n",
        "import keras.backend as K\n",
        "from keras.datasets import imdb\n",
        "from keras.layers import  LSTM, Embedding, TimeDistributed, Input, Dense\n",
        "from keras.models import Model\n",
        "from tensorflow.python.client import device_lib\n",
        "from tqdm import tqdm\n",
        "import os, random\n",
        "from argparse import ArgumentParser\n",
        "import numpy as np\n",
        "from tensorboardX import SummaryWriter\n",
        "from language_models import util\n",
        "import string\n",
        "from copy import deepcopy\n",
        "CHECK = 5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6gVMURlguFhx"
      },
      "source": [
        "## Helper Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e4ieQLdcXPQh"
      },
      "source": [
        "def generate_seq(model : Model, seed, size, temperature=1.0):\n",
        "    \"\"\"\n",
        "    :param model: The complete RNN language model\n",
        "    :param seed: The first few words of the sequence to start generating from\n",
        "    :param size: The total size of the sequence to generate\n",
        "    :param temperature: This controls how much we follow the probabilities provided by the network. For t=1.0 we just\n",
        "        sample directly according to the probabilities. Lower temperatures make the high-probability words more likely\n",
        "        (providing more likely, but slightly boring sentences) and higher temperatures make the lower probabilities more\n",
        "        likely (resulting in weirder sentences). For temperature=0.0, the generation is _greedy_, i.e. the word with the\n",
        "        highest probability is always chosen.\n",
        "    :return: A list of integers representing a samples sentence\n",
        "    \"\"\"\n",
        "\n",
        "    ls = seed.shape[0] # Length of seed\n",
        "\n",
        "    # Due to the way Keras RNNs work, we feed the model a complete sequence each time. At first it's just the seed,\n",
        "    # zero-padded to the right length. With each iteration we sample and set the next character.\n",
        "\n",
        "    tokens = np.concatenate([seed, np.zeros(size - ls)]) # Padding for the rest of the sentence\n",
        "    for i in range(ls, size):\n",
        "        probs = model.predict(tokens[None,:])\n",
        "\n",
        "        # Extract the i-th probability vector and sample an index from it\n",
        "        next_token = util.sample_logits(probs[0, i-1, :], temperature=temperature)\n",
        "        tokens[i] = next_token\n",
        "\n",
        "    return [int(t) for t in tokens]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DTfVACLTas7g"
      },
      "source": [
        "def sparse_loss(y_true, y_pred):\n",
        "  return K.sparse_categorical_crossentropy(y_true, y_pred, from_logits=True)\n",
        "\n",
        "def encode(seq,w2i):\n",
        "  words = [word.lower() for word in seq.split(' ')] \n",
        "  return np.array([w2i[word] if w2i.get(word) is not None else w2i['<UNK>'] for word in words])\n",
        "\n",
        "def decode(seq):\n",
        "  return ' '.join(i2w[id] for id in seq)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.special import softmax\n",
        "def calculate_prob_of_sentence(model : Model, sentence,w2i):\n",
        "    seq_encoded = encode(sentence,w2i)\n",
        "\n",
        "    prob = 1\n",
        "    tokens = np.concatenate([[seq_encoded[0]], np.zeros(len(seq_encoded) - 1)]) \n",
        "    for i in range(0, len(seq_encoded)):\n",
        "      probs = model.predict(tokens[None,:])\n",
        "      word_i_prob = softmax(softmax(probs[0, i-1, :]))[int(tokens[i])] \n",
        "      prob *= word_i_prob\n",
        "      tokens[i] = seq_encoded[i]\n",
        "\n",
        "    return prob"
      ],
      "metadata": {
        "id": "N99dkULFZesv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hkqo_rnwuOAy"
      },
      "source": [
        "### Defining Hyper-Parameters For Each Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5TmQF5d0bPjQ"
      },
      "source": [
        "class Args:\n",
        "  epochs = 20 # Number of epochs\n",
        "  embedding_size = 300 # Size of the word embeddings on the input layer.\n",
        "  out_every = 1 # Output every n epochs.\n",
        "  lr = 0.001 # Learning rate\n",
        "  batch = 128 # Batch size\n",
        "  task = 'wikisimple'\n",
        "  data = './data' # Data file. Should contain one sentence per line.\n",
        "  lstm_capacity = 256\n",
        "  max_length = None # Sentence max length.\n",
        "  top_words = 10000 # Word list size.\n",
        "  limit = None # Character cap for the corpus - not relevant in our exercise.\n",
        "  tb_dir = './runs/words' # Tensorboard directory\n",
        "  seed = 3 # RNG seed. Negative for random (seed is printed for reproducability).\n",
        "  extra = None # Number of extra LSTM layers.\n",
        "  reverse = False\n",
        "  name = \"\"\n",
        "\n",
        "options1 = Args() \n",
        "options1.name = \"1 LSTM Layer without Reverse\"\n",
        "options2 = deepcopy(options1)\n",
        "options2.reverse = True\n",
        "options2.name = \"1 LSTM Layer with Reverse\"\n",
        "options3 = deepcopy(options1) \n",
        "options3.extra = 1 \n",
        "options3.name = \"2 LSTM Layers without Reverse\"\n",
        "options4 = deepcopy(options2) \n",
        "options4.extra = 1 \n",
        "options4.name = \"2 LSTM Layers with Reverse\"\n",
        "options4.reverse = True\n",
        "\n",
        "\n",
        "options_list = [options1, options2, options3, options4] "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading Data"
      ],
      "metadata": {
        "id": "uLDceVH5PzKq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def split_data(data,train_size=0.8,val_size=0.1,test_size=0.1):\n",
        "  random.shuffle(data)\n",
        "  train_len = int(train_size*len(x))\n",
        "  val_len = int((train_size+val_size)*len(x))\n",
        "  return data[:train_len], data[train_len:val_len],data[val_len:]"
      ],
      "metadata": {
        "id": "kf5HmmCkTqGd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if options_list[0].seed < 0: # Same for all options..\n",
        "    seed = random.randint(0, 1000000)\n",
        "    print('random seed: ', seed)\n",
        "    np.random.seed(seed)\n",
        "else:\n",
        "    np.random.seed(options_list[0].seed)\n",
        "\n",
        "\n",
        "x, w2i, i2w = util.load_words(util.DIR + '/datasets/wikisimple.txt', vocab_size=options_list[0].top_words, limit=options_list[0].limit)\n",
        "x_max_len = max([len(sentence) for sentence in x])\n",
        "numwords = len(i2w)\n",
        "print('max sequence length ', x_max_len)\n",
        "print(numwords, 'distinct words')\n",
        "train_data,val_data,test_data = split_data(x)\n",
        "train_x = util.batch_pad(train_data, options_list[0].batch, add_eos=True) # Batching the train data\n",
        "val_x = util.batch_pad(val_data, options_list[0].batch, add_eos=True) # Batching the validation data\n",
        "test_x = util.batch_pad(test_data, options_list[0].batch, add_eos=True) # Batching the test data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e9zd3Yz1P8M_",
        "outputId": "9f1ae542-bd8d-45fd-92be-e0833727a957"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "raw data read\n",
            "max sequence length  132\n",
            "10000 distinct words\n",
            "max length per batch:  [15, 16, 16, 16, 16, 17, 17, 17, 17, 17, 17, 17, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 26, 26, 26, 26, 26, 26, 26, 26, 26, 27, 27, 27, 27, 27, 27, 27, 28, 28, 28, 28, 28, 28, 28, 28, 29, 29, 29, 29, 29, 30, 30, 30, 30, 30, 31, 31, 31, 31, 31, 32, 32, 32, 32, 33, 33, 33, 34, 34, 34, 34, 35, 35, 36, 36, 36, 37, 38, 38, 39, 39, 40, 41, 41, 42, 44, 45, 46, 47, 49, 52, 55, 62, 133]\n",
            "max length per batch:  [17, 18, 19, 19, 20, 20, 21, 21, 22, 22, 23, 24, 24, 25, 26, 27, 28, 30, 32, 34, 37, 42, 56, 88]\n",
            "max length per batch:  [17, 18, 19, 19, 20, 20, 21, 21, 22, 22, 23, 24, 24, 25, 26, 27, 28, 30, 31, 34, 36, 41, 55, 133]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create Models for Each Options"
      ],
      "metadata": {
        "id": "uBbXE2WZQhYo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def createModel(options):\n",
        "  input = Input(shape=(None, ))\n",
        "  embedding = Embedding(numwords, options.embedding_size, input_length=None)\n",
        "  embedded = embedding(input)\n",
        "\n",
        "  decoder_lstm = LSTM(options.lstm_capacity, return_sequences=True, go_backwards=options.reverse)\n",
        "  h = decoder_lstm(embedded)\n",
        "\n",
        "  if options.extra is not None:\n",
        "      for _ in range(options.extra):\n",
        "          h = LSTM(options.lstm_capacity, return_sequences=True)(h)\n",
        "\n",
        "  fromhidden = Dense(numwords, activation='linear')\n",
        "  out = TimeDistributed(fromhidden)(h)\n",
        "\n",
        "  model = Model(input, out)\n",
        "\n",
        "  opt = tf.keras.optimizers.Adam(learning_rate=options.lr)\n",
        "  lss = sparse_loss\n",
        "\n",
        "  model.compile(opt, lss)\n",
        "  return model\n"
      ],
      "metadata": {
        "id": "y0isAWGoQegn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "models = [createModel(options) for options in options_list]"
      ],
      "metadata": {
        "id": "g6nTSuSHQmGU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training"
      ],
      "metadata": {
        "id": "F2IQ06siQtKx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model,options,train_data):\n",
        "  epoch = 0\n",
        "  instances_seen = 0\n",
        "  \n",
        "  while epoch < options.epochs:\n",
        "      for batch in tqdm(train_data):\n",
        "          n, l = batch.shape\n",
        "\n",
        "          batch_shifted = np.concatenate([np.ones((n, 1)), batch], axis=1)  # prepend start symbol\n",
        "          batch_out = np.concatenate([batch, np.zeros((n, 1))], axis=1)     # append pad symbol\n",
        "\n",
        "          loss = model.train_on_batch(batch_shifted, batch_out[:, :, None]) # sum_over_batch_size - mean of mean for each class - [Sum over all samples {(Sum of differences between y_pred and y_target vector of each sample / No of element in y_target of the sample )}] / Batch_size\n",
        "\n",
        "          instances_seen += n\n",
        "          # tbw.add_scalar('lm/batch-loss', float(loss), instances_seen)\n",
        "      print(loss)\n",
        "      epoch += 1\n",
        "\n"
      ],
      "metadata": {
        "id": "gIJE_DCCNVGk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, model in enumerate(models):\n",
        "  print(f\"\\nTraining model {i + 1}, Type: {options_list[i].name}\\n\")\n",
        "  train(model, options_list[i],train_x)\n",
        "  print(\"-----------------------------------------------\\n\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oNxepzlWcgyw",
        "outputId": "fc8fcc29-1061-4973-f9a0-ff028e691f8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training model 1, Type: 1 LSTM Layer without Reverse\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 186/186 [00:26<00:00,  7.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.085677146911621\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 186/186 [00:11<00:00, 16.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.6336264610290527\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 186/186 [00:11<00:00, 15.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.5214264392852783\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 186/186 [00:11<00:00, 15.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.4688212871551514\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 186/186 [00:11<00:00, 15.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.407072067260742\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 186/186 [00:11<00:00, 15.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.36873197555542\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 186/186 [00:12<00:00, 15.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.3429222106933594\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 186/186 [00:11<00:00, 15.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.3400943279266357\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 186/186 [00:11<00:00, 15.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.286438465118408\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 186/186 [00:11<00:00, 15.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.236335515975952\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 186/186 [00:11<00:00, 15.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.2047863006591797\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 186/186 [00:11<00:00, 15.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.1972529888153076\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 186/186 [00:11<00:00, 15.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.1585071086883545\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 186/186 [00:11<00:00, 15.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.134404420852661\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 186/186 [00:11<00:00, 15.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.114643096923828\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 186/186 [00:11<00:00, 15.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.1019845008850098\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 186/186 [00:11<00:00, 15.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.061394453048706\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 186/186 [00:11<00:00, 15.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.084258794784546\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 186/186 [00:11<00:00, 15.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.0581746101379395\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 186/186 [00:11<00:00, 15.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.0297162532806396\n",
            "-----------------------------------------------\n",
            "\n",
            "\n",
            "\n",
            "Training model 2, Type: 1 LSTM Layer with Reverse\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 186/186 [00:16<00:00, 11.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5.57320499420166\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 186/186 [00:11<00:00, 15.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5.993616580963135\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 186/186 [00:11<00:00, 15.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5.503299713134766\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 186/186 [00:11<00:00, 15.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5.188401699066162\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 186/186 [00:11<00:00, 15.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.836703300476074\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 186/186 [00:11<00:00, 15.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.575553894042969\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 186/186 [00:12<00:00, 15.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.674558162689209\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 186/186 [00:12<00:00, 14.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.356936931610107\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 186/186 [00:12<00:00, 15.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.50731086730957\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 186/186 [00:12<00:00, 15.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.934467315673828\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 186/186 [00:12<00:00, 14.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.313580513000488\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 186/186 [00:12<00:00, 14.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.307985782623291\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 186/186 [00:12<00:00, 15.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.340573787689209\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 186/186 [00:12<00:00, 15.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.3197150230407715\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 186/186 [00:12<00:00, 15.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.437882423400879\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 186/186 [00:12<00:00, 15.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.197131156921387\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 186/186 [00:12<00:00, 15.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.394332408905029\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 186/186 [00:12<00:00, 15.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.058804988861084\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 186/186 [00:12<00:00, 15.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.999204635620117\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 186/186 [00:12<00:00, 15.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.926196575164795\n",
            "-----------------------------------------------\n",
            "\n",
            "\n",
            "\n",
            "Training model 3, Type: 2 LSTM Layers without Reverse\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 186/186 [00:22<00:00,  8.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5.1035027503967285\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 186/186 [00:14<00:00, 12.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5.008177757263184\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 186/186 [00:14<00:00, 13.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.868311882019043\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 186/186 [00:14<00:00, 13.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.999430179595947\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 186/186 [00:14<00:00, 13.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.354943752288818\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 186/186 [00:14<00:00, 13.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.014673233032227\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 186/186 [00:14<00:00, 13.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.8791215419769287\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 186/186 [00:14<00:00, 13.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.8351285457611084\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 186/186 [00:14<00:00, 13.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.832550525665283\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 186/186 [00:14<00:00, 13.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.6989619731903076\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 186/186 [00:14<00:00, 13.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.667938709259033\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 186/186 [00:14<00:00, 13.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.653604507446289\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 186/186 [00:14<00:00, 13.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.6253721714019775\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 186/186 [00:14<00:00, 13.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.5792863368988037\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 186/186 [00:14<00:00, 13.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.5390210151672363\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 186/186 [00:14<00:00, 12.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.5512499809265137\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 186/186 [00:14<00:00, 13.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.4846174716949463\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 186/186 [00:14<00:00, 13.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.462157964706421\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 186/186 [00:14<00:00, 13.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.468632459640503\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 186/186 [00:14<00:00, 13.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.4160122871398926\n",
            "-----------------------------------------------\n",
            "\n",
            "\n",
            "\n",
            "Training model 4, Type: 2 LSTM Layers with Reverse\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 186/186 [00:23<00:00,  8.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5.14104700088501\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 186/186 [00:14<00:00, 13.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5.076297760009766\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 186/186 [00:14<00:00, 12.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.931604862213135\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 186/186 [00:14<00:00, 12.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.941627025604248\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 186/186 [00:14<00:00, 12.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5.009622097015381\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 186/186 [00:14<00:00, 12.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5.015004634857178\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 186/186 [00:14<00:00, 13.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5.058128833770752\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 186/186 [00:14<00:00, 12.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5.085804462432861\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 186/186 [00:14<00:00, 13.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5.1164116859436035\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 186/186 [00:14<00:00, 13.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5.181401252746582\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 186/186 [00:14<00:00, 12.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5.0715508460998535\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 186/186 [00:14<00:00, 12.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5.025958061218262\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 186/186 [00:14<00:00, 13.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.787221431732178\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 186/186 [00:14<00:00, 12.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.6461262702941895\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 186/186 [00:14<00:00, 12.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.844838619232178\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 186/186 [00:14<00:00, 12.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.569586753845215\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 186/186 [00:14<00:00, 12.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.220826625823975\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 186/186 [00:14<00:00, 12.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.30557107925415\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 186/186 [00:14<00:00, 12.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.115988254547119\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 186/186 [00:14<00:00, 12.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.0285749435424805\n",
            "-----------------------------------------------\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preplexity based on Cross Entropy \n",
        "I used these articles [The relationship between Perplexity and Entropy in NLP](https://towardsdatascience.com/the-relationship-between-perplexity-and-entropy-in-nlp-f81888775ccc), [Perplexity in Language Models](https://towardsdatascience.com/perplexity-in-language-models-87a196019a94) and [Perplexity](https://en.wikipedia.org/wiki/Perplexity) wikipedia page to define the equation. "
      ],
      "metadata": {
        "id": "K_lKv0TagDBd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def perplexity(model,data):\n",
        "  loss = 0\n",
        "  count = 0\n",
        "  for batch in tqdm(data):\n",
        "    n, l = batch.shape\n",
        "\n",
        "    batch_shifted = np.concatenate([np.ones((n, 1)), batch], axis=1)  # prepend start symbol\n",
        "    batch_out = np.concatenate([batch, np.zeros((n, 1))], axis=1)     # append pad symbol\n",
        "\n",
        "    loss += model.evaluate(batch_shifted, batch_out[:, :, None],verbose=0) # sum_over_batch_size - mean of mean for each class - [Sum over all samples {(Sum of differences between y_pred and y_target vector of each sample / No of element in y_target of the sample )}] / Batch_size\n",
        "    count += 1 # count batch size\n",
        "  return 2**(loss/count) # return the mean perplexity for all batches in dataset.\n",
        "\n"
      ],
      "metadata": {
        "id": "e3dSivZGc_IS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res = 0\n",
        "for i, model in enumerate(models):\n",
        "  print(f\"*** Mean Perplexity On Model #{i + 1}, Type: {options_list[i].name} *** \")\n",
        "  print(\"Mean Perpelxity on Train:\", perplexity(model, train_x), \"\")\n",
        "  print(\"Mean Perpelxity on Validation:\", perplexity(model, val_x), \"\")\n",
        "  print(\"Mean Perpelxity on Test:\", perplexity(model, test_x), \"\")\n",
        "  print(\"-----------------------------------------------\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BdrRnyz3hnwS",
        "outputId": "8132661a-869d-4303-d356-5ba080faaf9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*** Mean Perplexity On Model #1, Type: 1 LSTM Layer without Reverse *** \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 186/186 [00:23<00:00,  8.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Perpelxity on Train: 17.353149501403344 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 24/24 [00:02<00:00,  8.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Perpelxity on Validation: 22.569151613170135 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 24/24 [00:02<00:00,  9.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Perpelxity on Test: 21.87317105854881 \n",
            "-----------------------------------------------\n",
            "*** Mean Perplexity On Model #2, Type: 1 LSTM Layer with Reverse *** \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 186/186 [00:23<00:00,  7.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Perpelxity on Train: 36.529504191141605 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 24/24 [00:02<00:00,  9.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Perpelxity on Validation: 50.82263765030222 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 24/24 [00:02<00:00,  9.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Perpelxity on Test: 49.214314395915615 \n",
            "-----------------------------------------------\n",
            "*** Mean Perplexity On Model #3, Type: 2 LSTM Layers without Reverse *** \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 186/186 [00:29<00:00,  6.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Perpelxity on Train: 42.98207399526106 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 24/24 [00:03<00:00,  7.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Perpelxity on Validation: 40.18241899530519 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 24/24 [00:03<00:00,  7.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Perpelxity on Test: 39.01121797010973 \n",
            "-----------------------------------------------\n",
            "*** Mean Perplexity On Model #4, Type: 2 LSTM Layers with Reverse *** \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 186/186 [00:29<00:00,  6.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Perpelxity on Train: 75.17726010657634 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 24/24 [00:02<00:00,  8.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Perpelxity on Validation: 74.27502421370822 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 24/24 [00:02<00:00,  8.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Perpelxity on Test: 72.49408848243262 \n",
            "-----------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Part 6 Generating sentences and calculating probabilities \n",
        "sentence = \"I love\"\n",
        "seed = encode(sentence,w2i)\n",
        "seed = np.insert(seed, 0, 1)\n",
        "for temp in [0, 1, 10]:\n",
        "  print('EMP ', temp)\n",
        "  for i, model in enumerate(models):\n",
        "    print(f\"\\tModel #{i}, name: {options_list[i].name}\")\n",
        "    gen = generate_seq(models[0], seed,  8, temperature=temp)\n",
        "    start_sen = decode(seed)\n",
        "    end_sen = decode(gen[len(seed):])\n",
        "    print(\"\\t\\tGenerated Sentence:\",start_sen + ' ' + end_sen)\n",
        "    print(\"\\t\\tProbability:\", calculate_prob_of_sentence(models[0],start_sen + ' ' + end_sen,w2i), \"\\n\")\n",
        "\n",
        "# Part 9\n",
        "for i, model in enumerate(models):\n",
        "  print(f\"Model #{i}, name: {options_list[i].name}\")\n",
        "  print(\"\\tSentence:\", \"<START> I love cupcakes\")\n",
        "  print(\"\\tProbability:\", calculate_prob_of_sentence(model, \"I love cupcakes\", w2i), \"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rdb19hDEbonW",
        "outputId": "eb89da51-956f-46b0-9929-8960d9af5039"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EMP  0\n",
            "\tModel #0, name: 1 LSTM Layer without Reverse\n",
            "\t\tGenerated Sentence: <START> i love lrb <UNK> rrb is a\n",
            "\t\tProbability: 1.0064280845696018e-32 \n",
            "\n",
            "\tModel #1, name: 1 LSTM Layer with Reverse\n",
            "\t\tGenerated Sentence: <START> i love lrb <UNK> rrb is a\n",
            "\t\tProbability: 1.0064280845696018e-32 \n",
            "\n",
            "\tModel #2, name: 2 LSTM Layers without Reverse\n",
            "\t\tGenerated Sentence: <START> i love lrb <UNK> rrb is a\n",
            "\t\tProbability: 1.0064280845696018e-32 \n",
            "\n",
            "\tModel #3, name: 2 LSTM Layers with Reverse\n",
            "\t\tGenerated Sentence: <START> i love lrb <UNK> rrb is a\n",
            "\t\tProbability: 1.0064280845696018e-32 \n",
            "\n",
            "EMP  1\n",
            "\tModel #0, name: 1 LSTM Layer without Reverse\n",
            "\t\tGenerated Sentence: <START> i love the <UNK> <UNK> husky lrb\n",
            "\t\tProbability: 1.007162582375041e-32 \n",
            "\n",
            "\tModel #1, name: 1 LSTM Layer with Reverse\n",
            "\t\tGenerated Sentence: <START> i love played the which must identical\n",
            "\t\tProbability: 1.0114295224984641e-32 \n",
            "\n",
            "\tModel #2, name: 2 LSTM Layers without Reverse\n",
            "\t\tGenerated Sentence: <START> i love lrb <UNK> yellow rrb also\n",
            "\t\tProbability: 1.0064530565992127e-32 \n",
            "\n",
            "\tModel #3, name: 2 LSTM Layers with Reverse\n",
            "\t\tGenerated Sentence: <START> i love the trophy should do not\n",
            "\t\tProbability: 1.0078906830792631e-32 \n",
            "\n",
            "EMP  10\n",
            "\tModel #0, name: 1 LSTM Layer without Reverse\n",
            "\t\tGenerated Sentence: <START> i love arenas education communities chapters bucking\n",
            "\t\tProbability: 1.0133654132480443e-32 \n",
            "\n",
            "\tModel #1, name: 1 LSTM Layer with Reverse\n",
            "\t\tGenerated Sentence: <START> i love geneva suzuki stalin roshal syria\n",
            "\t\tProbability: 1.0078561651930777e-32 \n",
            "\n",
            "\tModel #2, name: 2 LSTM Layers without Reverse\n",
            "\t\tGenerated Sentence: <START> i love maya starts rick trujillo subcultures\n",
            "\t\tProbability: 1.00641945242651e-32 \n",
            "\n",
            "\tModel #3, name: 2 LSTM Layers with Reverse\n",
            "\t\tGenerated Sentence: <START> i love define dates 175 monk daughter\n",
            "\t\tProbability: 1.0063782228738647e-32 \n",
            "\n",
            "Model #0, name: 1 LSTM Layer without Reverse\n",
            "\tSentence: <START> I love cupcakes\n",
            "\tProbability: 1.00077611671859e-12 \n",
            "\n",
            "Model #1, name: 1 LSTM Layer with Reverse\n",
            "\tSentence: <START> I love cupcakes\n",
            "\tProbability: 1.0149697434775756e-12 \n",
            "\n",
            "Model #2, name: 2 LSTM Layers without Reverse\n",
            "\tSentence: <START> I love cupcakes\n",
            "\tProbability: 1.0009231517135977e-12 \n",
            "\n",
            "Model #3, name: 2 LSTM Layers with Reverse\n",
            "\tSentence: <START> I love cupcakes\n",
            "\tProbability: 1.0012993960796718e-12 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get The Next Word - UI"
      ],
      "metadata": {
        "id": "wy32d307NXf0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = input('Enter a sentence : ')\n",
        "seed = encode(sentence,w2i)\n",
        "gen = generate_seq(models[0], seed, len(seed)+1, temperature=1.0)\n",
        "print(f\"The New Sentence is : {decode(gen)}\")"
      ],
      "metadata": {
        "id": "wbWkDvJS-PAV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67c70b7e-8a9f-441a-e569-ca1654cca54d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter a sentence : he is a former English football\n",
            "The New Sentence is : he is a former english football player\n"
          ]
        }
      ]
    }
  ]
}